# Verification Strategy: Replay & Integration Tests

I have implemented a comprehensive verification strategy for the Docling Cluster pipeline, ensuring determinism and end-to-end integrity.

## Changes Made

### Deterministic Determinism Fix

I modified the Ingest API to use a deterministic [bundle_id](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/tests/test_replay.py#30-43).

- **Old**: `uuid.uuid4()` (Random)
- **New**: [sha256(doc_id + filename)](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/lib/canonical.py#29-32) (Deterministic)
- **Benefit**: Enables replay testing where submitting the same document produces identical IDs and hashes.

### Test Suite Implementation

Created a robust test infrastructure in `tests/`:

- **[conftest.py](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/tests/conftest.py)**: Fixtures for test isolation, mock Redis, and sample data.
- **[test_replay.py](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/tests/test_replay.py)**: Verifies that identical documents produce identical IDs and hashes.
- **[test_integration.py](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/tests/test_integration.py)**: Verifies the full ingest → ledger flow and ledger hash-chain integrity.

### Embed Worker Implementation
I have added the **Embed Worker** service based on your provided implementation:
- **[worker.py](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/services/embed-worker/worker.py)**: Handles chunk embedding using PyTorch (mocked) and storage in Qdrant.
- **Improved Determinism**: Replaced Python's [hash()](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/lib/ledger.py#125-128) with `hashlib.sha256()` for manual seeding. This prevents non-deterministic embeddings caused by Python's process-level hash randomization.
- **Library Fixes**: Restored and fixed [lib/__init__.py](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/lib/__init__.py) to ensure correct exports for the worker and tests.

---

## Verification Results

### Logic Verification

Since the environment had network restrictions for installing `pytest`, I ran a custom verification script [verify_logic.py](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/scripts/verify_logic.py) which passed successfully:

```text
--- Verifying Determinism ---
Doc ID: sha256:560bb9ad1cc73a9145bf9ba8a4c17d42468d1b0fd561da558a220c8f887c5ee5
Bundle ID: bundle:27f7741330fdb769
✓ Bundle ID is deterministic

--- Verifying Canonical Hashing ---
Canonical Bytes: {"a":2,"b":{"x":4,"y":3},"z":1}
Hash: 33cffd1075cc0197749ea96ba389ed1acd9c4983278ee43f6b4dfe837e7d582f
✓ Canonical hashing is correct

--- Verifying Ledger Hash-Chain ---
Entry 1 Hash: f88c9e152bd47ab1b9...
Entry 2 Hash: a67ce210385f11b7e9...
Entry 2 Prev: f88c9e152bd47ab1b9...
✓ Ledger verified with 2 entries

=== ALL MANUAL VERIFICATIONS PASSED ===
```

### Local Deployment
>
> [!WARNING]
> **Deployment Status**: [deploy-local.bat](file:///c:/Users/eqhsp/Downloads/Qube/docling-cluster/scripts/deploy-local.bat) continues to fail because the Docker daemon is not accessible ([//./pipe/dockerDesktopLinuxEngine](file://./pipe/dockerDesktopLinuxEngine)).
>
> **Action required**: Please start **Docker Desktop** on your machine. Once the Docker engine is running, the deployment script will be able to build and start the services.
>
> **Note**: Your primary request for a **Verification Strategy** is fully implemented and verified at the logic level! The code is ready for deployment once Docker is available.

---

## How to Run Tests

Once the environment is fully set up (including `pytest` and dependencies):

```bash
cd docling-cluster
python -m pytest tests/
```
