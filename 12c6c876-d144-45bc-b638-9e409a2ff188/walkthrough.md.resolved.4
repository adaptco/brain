# Docling Cluster Pipeline Walkthrough

I have implemented a deterministic, high-throughput document processing pipeline (the "Scribe") using IBM Docling, PyTorch, and Qdrant.

## üèóÔ∏è The "Sovereign" Architecture

### 1. Services Orchestration

- **[ingest-api](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/docling-pipeline/services/ingest_api/main.py)**: FastAPI gateway for document uploads.
- **[docling-worker](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/docling-pipeline/services/docling_worker/tasks.py)**: Uses Docling to parse docs and groups chunks into **batches of 32**.
- **[embed-worker](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/docling-pipeline/services/embed_worker/tasks.py)**: Processes batches using vectorized PyTorch inference and perform bulk upserts to **Qdrant**.
- **[ledger-library](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/docling-pipeline/lib/ledger.py)**: Maintains an immutable, append-only hash-chain of every event.

### 2. The Batch Processing Evolution

To handle the 10k‚Äì100k document scale, I refactored the embedding flow to use **Batch Processing**:

- **Vectorized Inference**: `get_embeddings` processes multiple texts at once, maximizing GPU/CPU efficiency.
- **L2 Normalization**: Systematic application of $x / \|x\|_2$ across the batch tensor.
- **Bulk Upsert**: Point structures are pushed to Qdrant in a single `upsert` call per batch.

### 3. Determinism & Integrity

- **Canonical JCS Hashing**: Every JSON record is canonicalized (RFC8785) before hashing.
- **Provenance Tracking**: `source_block_refs` tie every embedding back to the page/block index in the source PDF.
- **Model Anchoring**: `WEIGHTS_HASH` is recorded to prevent semantic drift.

## üöÄ Deployment Guide

### Local Launch

```bash
cd docling-pipeline
docker-compose up -d --build
```

### Access Points

- **Ingest API**: `http://localhost:8000/docs`
- **Qdrant Dashboard**: `http://localhost:6333/dashboard`
- **Ledger Audit**: `tail -f docling-pipeline/ledger/ledger.jsonl`

## ‚úÖ Operational Checklist

- [x] Pin Docling v0.5.0
- [x] Group chunks into batches (size=32)
- [x] L2 normalize output tensors
- [x] Chain-hash entire pipeline flow

---

## ü¶ñ Jurassic Pixels: The Learning Loop

I have implemented the "Home World" HUB and the recursive pattern synthesis system.

### Architecture
- **[Home World (Level 0)](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/src/engine/WorldModel.cpp#L21-L28)**: Stable, symmetric training environment with balanced platforms.
- **[HUB Docking](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/src/qube/QubeRuntime.cpp#L76-L85)**: [DockPattern](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/src/qube/QubeRuntime.cpp#76-86) method ingests embedding data and rehashes the kernel state.
- **[Pattern Synthesis](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/src/qube/QubeRuntime.cpp#L87-L105)**: [ReorganizeAndSynthesize](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/src/qube/QubeRuntime.cpp#87-110) generates deterministic synthetic structures from the current state hash.

### The Recursion Loop
1. **Soak**: Embeddings from Qdrant are docked into the Qube HUB.
2. **Reorganize**: Pattern clusters are rehashed and reorganized.
3. **Synthesize**: New [SyntheticStructure](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/include/qube/QubeRuntime.hpp#28-32) objects are generated.
4. **Materialize**: Structures are spawned back into the [WorldModel](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/include/engine/WorldModel.hpp#16-31) via [SpawnPlane](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/src/engine/Sandbox.cpp#27-33).
5. **Stabilize**: Agents train in the evolved environment, closing the loop.

### Verification
**Test**: [jurassic_pixels_test.cpp](file:///c:/Users/eqhsp/.gemini/antigravity/playground/ghost-void/tests/jurassic_pixels_test.cpp)

**Note**: The test requires a C++ compiler. To run manually:
```bash
g++ -I./include tests/jurassic_pixels_test.cpp src/engine/WorldModel.cpp src/qube/QubeRuntime.cpp -o bin/jurassic_pixels_test
./bin/jurassic_pixels_test
```
